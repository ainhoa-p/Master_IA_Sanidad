{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.3.5 Mapas de activaci√≥n.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGTFXl2vJKKWvb2OkHZmnc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/Modulo_2/2_3_5_Mapas_de_activaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cveZSFPVsn1b"
      },
      "source": [
        "\"\"\"\n",
        "En esta libreta veremos un ejemplo de XXX\n",
        "\n",
        "Referencias: \n",
        " - https://nbviewer.org/github/vincent1bt/Healthy-notebooks/blob/master/AD.ipynb\n",
        " - https://vincentblog.xyz/posts/detecting-alzheimer-s-desease-with-deep-learning\n",
        "\"\"\"\n",
        "\n",
        "def get_activation_map(image_path, image_class_vector):        \n",
        "        image_loaded = PIL.Image.open(image_path)\n",
        "        image_loaded = image_loaded.resize((img_size, img_size))\n",
        "        image_loaded = np.asarray(image_loaded)\n",
        "      \n",
        "        if len(image_loaded.shape) < 3:\n",
        "          image_loaded = np.stack([image_loaded.copy()] * 3, axis=2)\n",
        "        \n",
        "        preprocessed_image = preprocess_input(image_loaded)\n",
        "        preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
        "        \n",
        "        image_class = np.argmax(image_class_vector)\n",
        "\n",
        "        class_weights = model.layers[-1].get_weights()[0]\n",
        "        final_conv_layer = model.layers[-3]\n",
        "        \n",
        "        get_output = tf.keras.backend.function([model.layers[0].input], \n",
        "                                               [final_conv_layer.output, model.layers[-1].output])\n",
        "        \n",
        "        [conv_outputs, predictions] = get_output(preprocessed_image)\n",
        "        conv_outputs = conv_outputs[0, :, :, :]\n",
        "\n",
        "        cam = np.zeros(dtype=np.float32, shape=conv_outputs.shape[0:2])\n",
        "\n",
        "        for index, weight in enumerate(class_weights[:, image_class]):\n",
        "          cam += weight * conv_outputs[:, :, index]\n",
        "        \n",
        "        class_predicted = np.argmax(predictions[0])\n",
        "        predictions = f'Class predicted: {class_predicted} | Real class: {image_class}'\n",
        "        \n",
        "        cam /= np.max(cam)\n",
        "        cam = cv2.resize(cam, (img_size, img_size))\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "        heatmap[np.where(cam < 0.2)] = 0\n",
        "        \n",
        "        img = heatmap * 0.5 + image_loaded\n",
        "        cv2.imwrite(\"heatmap.jpg\", img)\n",
        "        \n",
        "        heatmap = mpimg.imread(\"heatmap.jpg\")\n",
        "        \n",
        "        scaled_image = (((img - img.min()) * 255) / (img.max() - img.min())).astype(np.uint8)\n",
        "        \n",
        "        fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "        ax[0].imshow(image_loaded)\n",
        "\n",
        "        ax[0].set_title('Original image')\n",
        "\n",
        "        ax[1].imshow(heatmap)\n",
        "        ax[1].set_title(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}