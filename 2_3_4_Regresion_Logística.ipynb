{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOsQZVs+uMR7G16ZlSzHYR8",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/2_3_4_Regresion_Log%C3%ADstica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regresión logística"
   ],
   "metadata": {
    "id": "YKoHCRrL5J7e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Datos: ILPD (Indian Liver Patient Dataset) Data Set\n",
    "* [Descarga haciendo click en este enlace](https://github.com/txusser/Master_IA_Sanidad/blob/main/Modulo_2/datos/Indian_Liver_Patient_Dataset_(ILPD).csv)\n",
    "\n",
    "\n",
    "El Indian Liver Patient Dataset (ILPD) es un conjunto de datos utilizado para el análisis y la predicción de enfermedades hepáticas en pacientes. Este dataset proviene de una base de datos de pacientes indios y está destinado a ayudar en la identificación de personas que pueden estar sufriendo de enfermedades hepáticas basadas en varias características clínicas y bioquímicas.\n",
    "\n",
    "Características del Dataset:\n",
    "Número de instancias: 583 pacientes\n",
    "Número de variables/características: 10+1\n",
    "\n",
    "\n",
    "### Variables del dataset ILPD:\n",
    "\n",
    "1. **Age**: Edad del paciente\n",
    "   - **Descripción**: Indica la edad del paciente en años.\n",
    "\n",
    "2. **Gender**: Género del paciente\n",
    "   - **Descripción**: Indica el género del paciente, donde 'Male' corresponde a masculino y 'Female' a femenino.\n",
    "\n",
    "3. **Total_Bilirubin (TB)**: Bilirrubina total\n",
    "   - **Descripción**: La cantidad total de bilirrubina en la sangre. La bilirrubina es una sustancia amarilla que se produce durante la descomposición normal de los glóbulos rojos. Altos niveles pueden indicar problemas hepáticos.\n",
    "\n",
    "4. **Direct_Bilirubin (DB)**: Bilirrubina directa\n",
    "   - **Descripción**: La cantidad de bilirrubina conjugada en la sangre. La bilirrubina directa está unida a otras moléculas que la hacen soluble en agua y puede ser un indicador más específico de enfermedades hepáticas.\n",
    "\n",
    "5. **Alkaline_Phosphotase (Alkphos)**: Fosfatasa alcalina\n",
    "   - **Descripción**: Una enzima relacionada con el conducto biliar. Niveles elevados pueden indicar bloqueo del conducto biliar o enfermedad hepática.\n",
    "\n",
    "6. **Alamine_Aminotransferase (Sgpt)**: Alanina aminotransferasa\n",
    "   - **Descripción**: Una enzima que se encuentra principalmente en el hígado. Niveles elevados pueden ser un signo de daño hepático.\n",
    "\n",
    "7. **Aspartate_Aminotransferase (Sgot)**: Aspartato aminotransferasa\n",
    "   - **Descripción**: Una enzima que se encuentra en el hígado y en otros tejidos del cuerpo. Niveles elevados pueden indicar daño hepático.\n",
    "\n",
    "8. **Total_Proteins (TP)**: Proteínas totales\n",
    "   - **Descripción**: La cantidad total de proteínas en la sangre. Las proteínas son esenciales para la estructura y función de todas las células del cuerpo.\n",
    "\n",
    "9. **Albumin (ALB)**: Albúmina\n",
    "   - **Descripción**: Una proteína producida por el hígado que ayuda a mantener el volumen y la presión sanguínea. Niveles bajos pueden indicar problemas hepáticos.\n",
    "\n",
    "10. **Albumin_and_Globulin_Ratio (A/G Ratio)**: Relación albúmina y globulina\n",
    "    - **Descripción**: La proporción de albúmina a globulina en la sangre. Esta relación puede ayudar a identificar diferentes tipos de enfermedades hepáticas.\n",
    "\n",
    "11. **Dataset (Selector)**: Selector de datos\n",
    "    - **Descripción**: Campo utilizado para dividir los datos en dos conjuntos (etiquetados por expertos). Se usa generalmente para indicar si el paciente tiene una enfermedad hepática (1) o no (2).\n",
    "\n",
    "Espero que esta explicación te sea útil para comprender mejor el contenido y propósito de cada columna en el dataset ILPD."
   ],
   "metadata": {
    "id": "LmT3pvr67REf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías de Scikit-learn\n",
    "from sklearn.impute import SimpleImputer # Para imputación de valores faltantes\n",
    "from sklearn.preprocessing import LabelEncoder # Para codificación de variables categóticas\n",
    "from sklearn.preprocessing import StandardScaler # Para aplicar transformación de valores\n",
    "from statsmodels.tools import add_constant  # Para agregar una columna de unos (constante) al conjunto de datos\n",
    "import statsmodels.api as sm  # Para construir un modelo de regresión logística para selección de variables\n",
    "from scipy import stats  # Para realizar cálculos estadísticos\n",
    "from sklearn.linear_model import LogisticRegression # Modelo de regresión logística para ajustar los datos\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score # Métricas de evaluación del modelo\n",
    "import matplotlib.pyplot as plt # Librería para gráficas\n"
   ],
   "metadata": {
    "id": "GrD8MSXp_k8_"
   },
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Revisión y procesado de valores faltantes"
   ],
   "metadata": {
    "id": "J8jR_5N1-DgS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/content/Indian_Liver_Patient_Dataset_(ILPD).csv\")\n",
    "print(\"Columnas:\", df.columns)\n",
    "\n",
    "# Comprobamos el estado del conjunto de datos para ver si es necesario realizar\n",
    "# alguna operación de imputación de datos\n",
    "\n",
    "# Identificar valores faltantes\n",
    "conteo_valores_faltantes = df.isnull().sum()\n",
    "porcentaje_valores_faltantes = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Crear un DataFrame para mostrar el conteo y porcentaje de valores faltantes\n",
    "datos_faltantes = pd.DataFrame({\n",
    "    'Número': conteo_valores_faltantes,\n",
    "    'Porcentaje': porcentaje_valores_faltantes\n",
    "})\n",
    "\n",
    "print(f\" - Valores faltantes: \\n {datos_faltantes}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Es5vx5D0JPPI",
    "outputId": "3244d3ac-1a79-4433-cbf5-8941c4552213"
   },
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Imputación de valores faltantes utilizando el algoritmo SimpleImputer de scikit-learn\n",
    "# Rellenamos los valores faltantes teniendo en cuenta la mediana de la columna a\n",
    "# imputar. Nota: este procedimiento (imputación por la mediana) se realiza sobre\n",
    "# columnas de datos numéricos\n",
    "imputador = SimpleImputer(strategy='median')\n",
    "cols_numericas = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "df[cols_numericas] = imputador.fit_transform(df[cols_numericas])\n",
    "\n",
    "# Valores faltantes tras la operación\n",
    "print(f\" => Número de valores faltantes: \\n {df.isnull().sum()}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOaAmFVC8hO3",
    "outputId": "0e80a271-3b31-4bb6-dd25-1cbc69e4a17d"
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Transformación de datos"
   ],
   "metadata": {
    "id": "8-Wl1OGc-Iht"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Operaciones de transformación de datos\n",
    "\n",
    "# Transformar la columna 'SEXO' a variables numéricas utilizando Label Encoding\n",
    "print(\"Valores en la columna Sexo:\", np.unique(df['SEXO']))\n",
    "\n",
    "# Utilizamos un diccionario para hacer la codificación, de modo que mapeamos los\n",
    "# valores Male a 1 y Female a 0\n",
    "df['SEXO'] = df['SEXO'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Remapeamos también la variable objetivo para que tome valores dicotómicos 1 o 0\n",
    "df['CLASS'] = df['CLASS'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Verificar los tipos de datos y la transformación realizada\n",
    "print(\"\\n - Tipos de datos:\", df.dtypes)\n",
    "print(f\"\\n - Primeras filas del dataset tras la codificación de variables categóricas:\\n {df.head(10)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mF6cDWV198OL",
    "outputId": "b5f1e640-6431-4d75-f16e-d0a3b68d34dd"
   },
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Selección de características\n",
    "Vamos a ver cómo podemos utilizar un modelo de regresión logística para identificar las características más relevantes mediante la evaluación estadística de su capacidad predictiva. La selección de características es un paso crucial en la construcción de modelos de aprendizaje automático porque permite mejorar la interpretabilidad del modelo, reducir el sobreajuste (overfitting) y mejorar el rendimiento general del modelo.\n",
    "\n",
    "### Contexto del Proceso de Selección de Características:\n",
    "\n",
    "1. **Agregar una constante**:\n",
    "   - **Propósito**: Incluir un intercepto en el modelo de regresión logística. Esto permite al modelo ajustar correctamente la línea de base de la predicción.\n",
    "\n",
    "2. **Ajustar el modelo Logit**:\n",
    "   - **Propósito**: Entrenar el modelo de regresión logística utilizando las características del conjunto de datos. Esto implica encontrar los coeficientes que mejor relacionan las características independientes con la variable dependiente.\n",
    "\n",
    "3. **Evaluación del modelo**:\n",
    "   - **Propósito**: Evaluar la adecuación del modelo mediante el resumen del ajuste del modelo. El resumen incluye métricas como los coeficientes, errores estándar, valores p, etc.\n",
    "\n",
    "4. **Selección de características basadas en valores p**:\n",
    "   - **Propósito**: Identificar qué características son estadísticamente significativas en la predicción de la variable objetivo. Los valores p proporcionan una medida de la probabilidad de que los coeficientes observados sean diferentes de cero por azar.\n",
    "   - **Proceso**: Se consideran características relevantes aquellas cuyos valores p son menores a un umbral (típicamente 0.05), lo que indica que hay menos del 5% de probabilidad de que la asociación observada se deba al azar.\n",
    "\n",
    "### Importancia del Proceso:\n",
    "\n",
    "- **Reducción de la Dimensionalidad**: Al identificar y seleccionar solo las características más relevantes, se puede reducir el número de variables en el modelo, lo que simplifica el modelo y puede mejorar su rendimiento.\n",
    "- **Mejora del Rendimiento del Modelo**: Eliminar características irrelevantes o redundantes puede mejorar la precisión del modelo y reducir el riesgo de sobreajuste.\n",
    "- **Interpretabilidad**: Un modelo con menos características es más fácil de interpretar y entender, lo que es crucial en muchas aplicaciones, especialmente en el ámbito médico o financiero.\n",
    "- **Eficiencia Computacional**: Modelos más simples requieren menos recursos computacionales para ser entrenados y evaluados.\n",
    "\n",
    "En resumen, el proceso de selección de características utilizando un modelo de regresión logística y valores p es una técnica poderosa para construir modelos predictivos efectivos y eficientes, permitiendo a los analistas concentrarse en las variables que realmente importan."
   ],
   "metadata": {
    "id": "_YpsY1e_CnF5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Agregar una constante al conjunto de características\n",
    "X = df.drop('CLASS', axis=1)\n",
    "\n",
    "df_constant = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo Logit\n",
    "model = sm.Logit(df['CLASS'], df_constant)\n",
    "resultado = model.fit()\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "print(f\" - Resultados: {resultado.summary()}\")\n",
    "\n",
    "# Veámos cuáles son las características más relevantes\n",
    "\n",
    "p_values = resultado.pvalues\n",
    "relevant_features = p_values[p_values < 0.05].index.tolist()\n",
    "\n",
    "# Eliminamos la constante de las características relevantes si está presente\n",
    "if 'const' in relevant_features:\n",
    "    relevant_features.remove('const')\n",
    "\n",
    "print(\"Características relevantes a partir de los p-values:\", relevant_features)\n",
    "print(\"- Valores p:\\n\", p_values)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbbfSp9NxhoU",
    "outputId": "444c0a64-bae4-4575-c8c1-b4e3c32da451"
   },
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comentarios:\n",
    "\n",
    "Los resultados anteriores muestran un valor P superior al recomendado (5%) para algunas características. Esto implica que tienen una baja relación estadística con la probabilidad de enfermedad cardíaca.\n",
    "\n",
    "A continuación, utilizaremos la técnica de eliminación retrospectiva para deshacernos de aquellas variables que aportan menor información. En [este enlace](https://medium.com/@abhinav.mahapatra10/ml-basics-feature-selection-part-2-3b9b3e71c14a) encontrarás más información acerca de esta técnica de selección de características.\n",
    "\n",
    "La técnica de eliminación retrospectiva consiste en eliminar una por una las variables menos significativas, seguido de la ejecución de la regresión repetidamente hasta que todos los atributos tengan valores P inferiores a 0,05.\n",
    "\n",
    "Otras referencia:\n",
    "* [Regresión lineal múltiple (técnica de eliminación hacia atrás)](https://barcelonageeks.com/ml-regresion-lineal-multiple-tecnica-de-eliminacion-hacia-atras/)\n"
   ],
   "metadata": {
    "id": "h-TkL1ygynOw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def back_feature_elem(df, dep_var, cols):\n",
    "    \"\"\"\n",
    "    Toma el DataFrame, la variable dependiente y una lista de nombres de columnas.\n",
    "    Ejecuta repetidamente una regresión logística eliminando la característica con el valor P más alto por encima de un umbral alfa\n",
    "    en cada iteración, hasta que todos los valores P sean menores que alfa, devolviendo el resumen de la regresión final.\n",
    "    \"\"\"\n",
    "    while len(cols) > 0:  # Continúa el proceso hasta que no quedan columnas por evaluar\n",
    "        model = sm.Logit(dep_var, df[cols])  # Crea un modelo logístico con las columnas actuales\n",
    "        result = model.fit(disp=0)  # Ajusta el modelo sin mostrar el proceso\n",
    "        largest_pvalue = round(result.pvalues, 3).nlargest(1)  # Encuentra el valor P más alto y lo redondea a tres decimales\n",
    "        if largest_pvalue.iloc[0] < 0.05:  # Si el valor P más alto es menor que 0.05, devuelve el resultado\n",
    "            return result\n",
    "        else:\n",
    "            # Elimina la columna con el valor P más alto de la lista de columnas\n",
    "            cols.remove(largest_pvalue.index[0])  # Elimina la columna por nombre\n",
    "\n",
    "# Suponiendo que 'df_constant' es tu DataFrame y 'df' es otro DataFrame con la variable dependiente\n",
    "if 'const' not in df_constant.columns:\n",
    "    df_constant['const'] = 1\n",
    "cols = df_constant.columns.tolist()  # Suponiendo que df_constant está definido y tiene las columnas apropiadas\n",
    "\n",
    "def calculate_vif(df, cols):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = cols\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df[cols].values, i) for i in range(len(cols))]\n",
    "    return vif_data\n",
    "\n",
    "# Calcular VIF\n",
    "vif_df = calculate_vif(df_constant, cols)\n",
    "print(vif_df)\n",
    "\n",
    "# Eliminar variables con VIF muy alto (e.g., VIF > 10)\n",
    "cols = [col for col in cols if vif_df[vif_df['feature'] == col]['VIF'].values[0] < 10]\n",
    "\n",
    "\n",
    "result = back_feature_elem(df_constant, df['CLASS'], cols)\n",
    "print(result.summary())  # Muestra el resumen del modelo final\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFfB5rSIz0TP",
    "outputId": "47910d95-f45f-4bdf-9314-cfd2b0166210"
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Entrenamiento del modelo"
   ],
   "metadata": {
    "id": "wcSz1s9yFytg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Seleccionamos las características con las que entrenar nuestro modelo a\n",
    "# partir de los resultados anteriores\n",
    "\n",
    "X = df[relevant_features] # Matrix de características\n",
    "y = df['CLASS'] # Vectore de clase (variable objetivo)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=5)\n",
    "print(\"X train shape:\", X_train.shape)\n",
    "print(\"y train shape:\", y_train.shape)\n",
    "print(\"y_train diez primeros valores:\", y_train[:10])"
   ],
   "metadata": {
    "id": "QvTJlbYW-iqS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrenamos y evaluamos el modelo resultante"
   ],
   "metadata": {
    "id": "gV7MxcLjAQB5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Entrenar el modelo de regresión logística\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predecir sobre el conjunto de prueba\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluar la precisión del modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(50 * \"*\")\n",
    "print(\"\\n => Precisión del modelo: => {:.2f}\".format(acc))\n",
    "\n",
    "# Mostrar un informe de clasificación más detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXCUNS3RAVPx",
    "outputId": "f00cdad2-97d9-454a-def1-b19cdf480daf"
   },
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Representar la curva ROC\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "m505tqatIJNm",
    "outputId": "067e70aa-e963-42b9-cc68-9b3cc980a04f"
   },
   "execution_count": 107,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir de los resultados de la evaluación del modelo, podemos extraer varias conclusiones sobre su desempeño. Aquí hay un desglose de los resultados y lo que implican:\n",
    "\n",
    "### Resultados:\n",
    "\n",
    "1. **Precisión del modelo (accuracy)**: 0.70\n",
    "   - **Descripción**: La precisión del modelo es del 70%, lo que significa que el modelo clasifica correctamente el 70% de las instancias del conjunto de prueba.\n",
    "\n",
    "2. **Informe de clasificación**:\n",
    "   - **Clases**:\n",
    "     - `0`: No tiene enfermedad hepática.\n",
    "     - `1`: Tiene enfermedad hepática.\n",
    "   \n",
    "   - **Métricas por clase**:\n",
    "     - **Precisión (precision)**:\n",
    "       - Clase `0`: 0.58\n",
    "       - Clase `1`: 0.71\n",
    "     - **Recuperación (recall)**:\n",
    "       - Clase `0`: 0.19\n",
    "       - Clase `1`: 0.94\n",
    "     - **F1-score**:\n",
    "       - Clase `0`: 0.29\n",
    "       - Clase `1`: 0.81\n",
    "     - **Soporte (support)**:\n",
    "       - Clase `0`: 37 instancias\n",
    "       - Clase `1`: 80 instancias\n",
    "\n",
    "   - **Promedios**:\n",
    "     - **Macro promedio (macro avg)**:\n",
    "       - Precisión: 0.65\n",
    "       - Recuperación: 0.56\n",
    "       - F1-score: 0.55\n",
    "     - **Promedio ponderado (weighted avg)**:\n",
    "       - Precisión: 0.67\n",
    "       - Recuperación: 0.70\n",
    "       - F1-score: 0.64\n",
    "\n",
    "### Conclusiones:\n",
    "\n",
    "1. **Desempeño General**:\n",
    "   - El modelo tiene una precisión general del 70%, lo que sugiere que en general realiza una predicción correcta en el 70% de los casos.\n",
    "\n",
    "2. **Desempeño por Clase**:\n",
    "   - **Clase `0` (No tiene enfermedad hepática)**:\n",
    "     - La precisión es baja (0.58), lo que indica que, cuando el modelo predice que un paciente no tiene enfermedad hepática, solo es correcto el 58% de las veces.\n",
    "     - La recuperación es muy baja (0.19), lo que significa que solo identifica correctamente el 19% de los pacientes que realmente no tienen enfermedad hepática.\n",
    "     - El F1-score es bajo (0.29), reflejando el bajo equilibrio entre precisión y recuperación para esta clase.\n",
    "   \n",
    "   - **Clase `1` (Tiene enfermedad hepática)**:\n",
    "     - La precisión es alta (0.71), indicando que el modelo es correcto el 71% de las veces cuando predice que un paciente tiene enfermedad hepática.\n",
    "     - La recuperación es muy alta (0.94), lo que significa que identifica correctamente el 94% de los pacientes que realmente tienen enfermedad hepática.\n",
    "     - El F1-score es alto (0.81), lo que refleja un buen equilibrio entre precisión y recuperación para esta clase.\n",
    "\n",
    "3. **Desbalance de Clases**:\n",
    "   - Hay un desbalance en el número de instancias entre las clases (37 para `0` y 80 para `1`), lo que puede influir en las métricas de desempeño.\n",
    "   - El modelo parece estar mejor ajustado para identificar pacientes con enfermedad hepática (clase `1`) en comparación con los que no la tienen (clase `0`).\n",
    "\n",
    "### Implicaciones:\n",
    "\n",
    "- **Necesidad de Ajuste**: El bajo desempeño en la clase `0` sugiere que el modelo puede necesitar ajustes, tales como técnicas de balanceo de clases (submuestreo, sobremuestreo) o ajuste de los umbrales de decisión.\n",
    "- **Evaluación del Riesgo**: En contextos médicos, identificar correctamente a los pacientes que tienen una enfermedad es crucial. Sin embargo, el modelo también debe mejorar en la identificación de aquellos que no la tienen para evitar falsos positivos.\n",
    "\n",
    "### Próximos Pasos:\n",
    "\n",
    "- **Ajustar el Modelo**: Considerar técnicas para manejar el desbalance de clases y mejorar la precisión y recuperación de la clase `0`.\n",
    "- **Validación Cruzada**: Utilizar validación cruzada para obtener una mejor evaluación del desempeño general del modelo.\n",
    "- **Explorar Otros Modelos**: Evaluar otros algoritmos de clasificación que puedan manejar mejor el desbalance de clases y mejorar el rendimiento general.\n",
    "\n",
    "En resumen, aunque el modelo muestra un buen desempeño para la clase que indica enfermedad hepática, necesita mejoras significativas para identificar correctamente a los pacientes que no tienen la enfermedad."
   ],
   "metadata": {
    "id": "lvwCMb-cIwTw"
   }
  }
 ]
}
