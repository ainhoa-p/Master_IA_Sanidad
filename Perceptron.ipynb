{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN70bGP9993pgvaAcfm7VvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4og5pe10JM"
      },
      "source": [
        "Primero importamos las librerías que vayamos a necesitar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2dbryHd0whh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGznauIQ2XyM"
      },
      "source": [
        "Vamos a crear una clase Perceptron, que incluirá las variables que necesitaremos para hacer funcionar nuestro perceptron\n",
        "Fijamos el bias a 1, como es común para una neurona, y inicializamos dos variables vacias para los pesos y los errores. También definimos el ratio de entrenamiento (lr) y el número de iteraciones (epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vVFnaHF2TMA"
      },
      "source": [
        "class Perceptron(object):\n",
        "    def __init__(self, lr=0.01, epochs=2000):\n",
        "        self.lr = lr\n",
        "        self.bias = 1\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.errors_ = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24U-PpYx2qdf"
      },
      "source": [
        "Definimos una función encargada de realizar el cálculo y=w_0+w_1+⋯+w_n\n",
        "La función np.dot multiplica dos vectores elemento a elemento, que es lo que necesitamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeyEtQTI26NK"
      },
      "source": [
        "    def __linear(self, X):\n",
        "        return np.dot(X, self.weights[1:]) + self.weights[0] "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwb8l4Yc3R3P"
      },
      "source": [
        "Ahora definimos una función de activación. El siguiente comando utilizando np.where nos devolverá el valor 1 cuando la entrada sea >0 y y el valor 0 en el resto de los casos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jflIV3Uj3ckB"
      },
      "source": [
        "    def __activation(self, Y):\n",
        "        return np.where(Y>=0, 1, 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2j6WK5n_PrC"
      },
      "source": [
        "Ahora queda la parte compleja, que es el entrenamiento de la red. Para cada una de las entradas, calculamos y_hat, que será la label estimada pos la red, y la comparamos con y_target (las labels del dataset de entrenamiento). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbW1s0H8_P80"
      },
      "source": [
        "    def fit(self, X, y):\n",
        "        \n",
        "        assert len(X) == len(y), \"X e Y deben tener la misma longitud\"\n",
        "        \n",
        "        # Inicializa los pesos a 0, menos el peso del bias \n",
        "        # que se inicializa a 1 (self.bias)\n",
        "        weights = np.zeros(X.shape[1])\n",
        "        self.weights = np.insert(weights, 0, self.bias, axis=0)\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            errors = 0\n",
        "            for xi, y_target in zip(X, y):\n",
        "                z = self.__linear(xi)  # Suma ponderada\n",
        "                y_hat = self.__activation(z)  # Función de activación\n",
        "                # Calculamos la diferencia entre entrada y salida, \n",
        "                # y aplicamos el learning rate\n",
        "                delta = self.lr * (y_target - y_hat)  \n",
        "        \n",
        "                # Utilizmaos el parámetro delta calculado \n",
        "                # para actualizar los pesos\n",
        "                self.weights[1:] += delta * xi\n",
        "                self.weights[0] += delta\n",
        "                \n",
        "                errors += int(delta != 0.0)\n",
        "\n",
        "            self.errors_.append(errors)\n",
        "            #Interrumpimos el entrenamiento si el error es 0          \n",
        "            if not errors:\n",
        "                break"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psvwxdcD_y0t"
      },
      "source": [
        "Función auxiliar 1: Vamos a hacer uso de la función accuracy_score de sklearn para calcular el rendimiento de nuestro perceptron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv-1sANJ_y9M"
      },
      "source": [
        "    def score(sef, predictions, labels):\n",
        "        return accuracy_score(labels, predictions)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITWzko9yFBeL"
      },
      "source": [
        "Función auxiliar 2: Función de representación visual para nuestro perceptrón\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3kIs0j6FBmW"
      },
      "source": [
        "    def plot(self, predictions, labels):\n",
        "        assert type(self.weights) != 'NoneType',  \"Entrena el modelo primero.\"\n",
        "        plt.figure(figsize=(10,8))\n",
        "        plt.grid(True)\n",
        "\n",
        "        for input, target in zip(predictions, labels):\n",
        "            plt.plot(input[0],input[1],'ro' if (target == 1.0) else 'go')\n",
        "\n",
        "        for i in np.linspace(np.amin(predictions[:,:1]),np.amax(predictions[:,:1])):\n",
        "            slope = -(self.weights[0]/self.weights[2])/(self.weights[0]/self.weights[1])  \n",
        "            intercept = -self.weights[0]/self.weights[2]\n",
        "\n",
        "            # y = mx+b, equation of a line. mx = slope, n = intercept\n",
        "            y = (slope*i) + intercept\n",
        "            plt.plot(i, y, color='black', marker='x', linestyle='dashed')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttj820LvFpip"
      },
      "source": [
        "Finalmente, introducimos la función de predicción, que nos valdrá para hacer inferencia con nuevos datos una vez calculados los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0043EQOFptw"
      },
      "source": [
        "    def predict(self, X):\n",
        "        assert type(self.weights) != 'NoneType', \"Entrena el modelo primero.\"\n",
        "        y_hat = np.zeros(X.shape[0],)\n",
        "        for i, xi in enumerate(X):\n",
        "            y_hat[i] = self.__activation(self.__linear(xi))\n",
        "        return y_hat"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}