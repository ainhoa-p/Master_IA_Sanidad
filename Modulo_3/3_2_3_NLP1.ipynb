{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrf9GOG92JXSXHbtrng7gd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/txusser/Master_IA_Sanidad/blob/main/Modulo_3/NLP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos algunas dependencias."
      ],
      "metadata": {
        "id": "VVHdPxQ2mzJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er3LAaC_de9Z",
        "outputId": "1e1257fb-2a2b-48f1-b6c8-28900823ff69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘tutorial’: File exists\n",
            "fatal: destination path 'scikit-learn' already exists and is not an empty directory.\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!mkdir tutorial\n",
        "!git clone https://github.com/scikit-learn/scikit-learn.git\n",
        "!pip install scikit-learn\n",
        "!cp -r scikit-learn/doc/tutorial/text_analytics/ tutorial\n",
        "!python tutorial/text_analytics/data/twenty_newsgroups/fetch_data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos descargamos el dataset que vamos a utilizar en este ejemplo. \n",
        "Es un dataset de e-mails (aproximadamente 12.000 documentos en total), divididos (casi) uniformemente en 20 grupos de dependiendo de los temas que se tratan. Fue recopilado originalmente por Ken Lang, probablemente para su artículo \"Newsweeder: Learning to filter netnews\"."
      ],
      "metadata": {
        "id": "UxdxM3tam2d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train',shuffle=True)\n",
        "twenty_train.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaOOU0yThwVK",
        "outputId": "6c97a95d-975b-43b3-fe10-6a8ceeadbdc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(twenty_train.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Ibf9SEkl3N",
        "outputId": "565a3107-1266-4f32-8b4e-f06121f82f29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in twenty_train.target[:10]:\n",
        "  print(twenty_train.target_names[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YiX4hTPkoYS",
        "outputId": "276d5b71-dfd3-46af-b88a-7558d987db04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rec.autos\n",
            "comp.sys.mac.hardware\n",
            "comp.sys.mac.hardware\n",
            "comp.graphics\n",
            "sci.space\n",
            "talk.politics.guns\n",
            "sci.med\n",
            "comp.sys.ibm.pc.hardware\n",
            "comp.os.ms-windows.misc\n",
            "comp.sys.mac.hardware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(twenty_train.data[4].split(\"\\n\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPLB6Pr4k53J",
        "outputId": "2a340259-34e8-4237-ac30-45d95e7fc093"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\n",
            "Subject: Re: Shuttle Launch Question\n",
            "Organization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\n",
            "Distribution: sci\n",
            "Lines: 23\n",
            "\n",
            "From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\n",
            ">>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\n",
            ">>>\"Clear caution & warning memory.  Verify no unexpected\n",
            ">>>errors. ...\".  I am wondering what an \"expected error\" might\n",
            ">>>be.  Sorry if this is a really dumb question, but\n",
            "> \n",
            "> Parity errors in memory or previously known conditions that were waivered.\n",
            ">    \"Yes that is an error, but we already knew about it\"\n",
            "> I'd be curious as to what the real meaning of the quote is.\n",
            "> \n",
            "> tom\n",
            "\n",
            "\n",
            "My understanding is that the 'expected errors' are basically\n",
            "known bugs in the warning system software - things are checked\n",
            "that don't have the right values in yet because they aren't\n",
            "set till after launch, and suchlike. Rather than fix the code\n",
            "and possibly introduce new bugs, they just tell the crew\n",
            "'ok, if you see a warning no. 213 before liftoff, ignore it'.\n",
            "\n",
            " - Jonathan\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎El preprocesamiento de texto, la tokenización y el filtrado de palabras clave se incluyen en ‎‎CountVectorizer‎‎, que crea un diccionario de características y transforma los emails en vectores de características:.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUY4B2CZmHSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1IcAbgEmGBN",
        "outputId": "b26978dd-62bb-44f0-8b1c-015def691f59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el tamaño de nuestro vocabulario"
      ],
      "metadata": {
        "id": "eBC7fvLYnmhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect.vocabulary_.get(u'algorithm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSgE1nRKmcoA",
        "outputId": "20c5ddfb-6a16-4f99-c830-a2895a40a1f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27366"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎El recuento de ocurrencias es un buen comienzo, pero hay un problema: los documentos más largos tendrán valores de recuento promedio más altos que los documentos más cortos, aunque puedan hablar sobre los mismos temas.‎\n",
        "\n",
        "‎Para evitar estas posibles discrepancias basta con dividir el número de apariciones de cada palabra en un documento por el número total de palabras en el documento: estas nuevas características se denominan Frecuencias de Término (tf).\n",
        "\n",
        "‎Otro refinamiento además de transformar los valores en tf es reducir los pesos de las palabras que aparecen en muchos documentos del corpus y, por lo tanto, son menos informativas que las que ocurren solo en una porción más pequeña del corpus.‎\n",
        "\n",
        "‎Esta reducción de escala se denomina ‎‎tf-idf‎‎ para \"Term Frequency times Inverse Document Frequency\".‎\n",
        "\n",
        "‎Tanto ‎‎tf‎‎ como ‎‎tf-idf‎‎ se pueden calcular de la siguiente manera utilizando ‎‎TfidfTransformer‎‎:‎"
      ],
      "metadata": {
        "id": "ckXmYRmFmwmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)"
      ],
      "metadata": {
        "id": "nFMQVy0Wmv3C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎En el código de ejemplo anterior, en primer lugar usamos el método \"*fit*\" para ajustar nuestro estimador a los datos y, en segundo lugar, el método \"*transform*\" para transformar nuestra matriz de conteo en una representación tf-idf. Estos dos pasos se pueden combinar para lograr el mismo resultado final al omitir el procesamiento redundante. Esto se hace mediante el uso del método \"*fit_transform*\". Ejercicio: Reemplazar por el método \"*fit_transform*\""
      ],
      "metadata": {
        "id": "e6WF2nGXpeUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgYViQgKragf",
        "outputId": "04edae2e-b2b3-4829-88e1-22a67e54ab01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎Ahora que tenemos nuestras features, podemos entrenar un clasificador para que intente predecir la categoría de un post. Comencemos con un clasificador ‎‎naive Bayes, que proporciona una buena línea de base para esta tarea. Existen varias variantes de este clasificador; la más adecuada para el recuento de palabras es la variante multinomial"
      ],
      "metadata": {
        "id": "Tuoio1urp69F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "metadata": {
        "id": "LdbUVaE6psDm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para tratar de predecir el resultado en un nuevo documento, necesitamos extraer las características utilizando casi la misma cadena de extracción de características que antes. La diferencia es que llamamos a \"*transform*\" en lugar de a \"*fit_transform*\", ya que ya se han ajustado al conjunto de entrenamiento"
      ],
      "metadata": {
        "id": "9AzXLVMWqhec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new = ['Jesus Loves You. Follow his guidance and you will be able to reach heaven', 'Earth is 7 light years away from the sun','You need to ensure that the engine temperature does not reach above 90 degrees']\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "  print('%r => %s' % (doc, twenty_train.target_names[category]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxTyIfRWqzDe",
        "outputId": "80b689e6-737a-4a99-8d65-0d192f63e8ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Jesus Loves You. Follow his guidance and you will be able to reach heaven' => soc.religion.christian\n",
            "'Earth is 7 light years away from the sun' => sci.space\n",
            "'You need to ensure that the engine temperature does not reach above 90 degrees' => rec.autos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎Para que el vectorizador = > transformador = > clasificador sea más fácil de trabajar, proporciona una clase ‎‎Pipeline‎‎ que se comporta como un clasificador compuesto"
      ],
      "metadata": {
        "id": "GcgF5dn7f2iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "id": "vs8gS5lqf1bk",
        "outputId": "5a9f7feb-b6c9-43c7-820b-e58bab290a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos utilizar la misma base de datos para evaluar la precisión predictiva del modelo. Para eso, la base de datos reserva una porción test:‎\n",
        "\n"
      ],
      "metadata": {
        "id": "JXNZlDrsea7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test',shuffle=True)\n",
        "docs_test = twenty_test.data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "id": "XEr0slHIr6hw",
        "outputId": "f191a182-17b9-4961-9a3c-1e589292f118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎Logramos una precisión de alrededor del 75%. Veamos si podemos hacerlo mejor con una support vector machine (SVM),‎‎ que es ampliamente considerado como uno de los mejores algoritmos de clasificación de texto (aunque también es un poco más lento que el naive Bayes):‎\n",
        "\n"
      ],
      "metadata": {
        "id": "zNW8CZEzgIZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42,max_iter=5, tol=None))])\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "id": "6iSo8XeagW-R",
        "outputId": "b1e16dfd-b932-4f9d-9ce3-8c1d7d7d6354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8248805098247477"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos subido alrededor de un 5% en rendimiento utilizando una SVM. scikit-learn‎ proporciona más utilidades para un análisis de rendimiento más detallado de los resultados:‎"
      ],
      "metadata": {
        "id": "1Vd-d5Ixg1rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))\n"
      ],
      "metadata": {
        "id": "kHvj1KQhg0b7",
        "outputId": "4545ac00-edf3-4630-ec79-27cada53207e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.73      0.71      0.72       319\n",
            "           comp.graphics       0.78      0.72      0.75       389\n",
            " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
            "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
            "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
            "          comp.windows.x       0.84      0.76      0.80       395\n",
            "            misc.forsale       0.84      0.90      0.87       390\n",
            "               rec.autos       0.91      0.90      0.90       396\n",
            "         rec.motorcycles       0.93      0.96      0.95       398\n",
            "      rec.sport.baseball       0.88      0.90      0.89       397\n",
            "        rec.sport.hockey       0.88      0.99      0.93       399\n",
            "               sci.crypt       0.84      0.96      0.90       396\n",
            "         sci.electronics       0.83      0.62      0.71       393\n",
            "                 sci.med       0.87      0.86      0.87       396\n",
            "               sci.space       0.84      0.96      0.90       394\n",
            "  soc.religion.christian       0.76      0.94      0.84       398\n",
            "      talk.politics.guns       0.70      0.92      0.80       364\n",
            "   talk.politics.mideast       0.90      0.93      0.92       376\n",
            "      talk.politics.misc       0.89      0.55      0.68       310\n",
            "      talk.religion.misc       0.85      0.41      0.55       251\n",
            "\n",
            "                accuracy                           0.82      7532\n",
            "               macro avg       0.83      0.81      0.81      7532\n",
            "            weighted avg       0.83      0.82      0.82      7532\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in twenty_train.target_names:\n",
        "  for j in twenty_train.target_names:\n",
        "    if i!=j and metrics.confusion_matrix(twenty_test.target, predicted)[twenty_train.target_names.index(i),twenty_train.target_names.index(j)]>20:\n",
        "      print ('%s  -  %s = %s' % (i,j,metrics.confusion_matrix(twenty_test.target, predicted)[twenty_train.target_names.index(i),twenty_train.target_names.index(j)])) "
      ],
      "metadata": {
        "id": "Vli1czrzgjRx",
        "outputId": "13feeb80-82e4-4fd0-d050-cabdcaf176c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism  -  soc.religion.christian = 44\n",
            "comp.graphics  -  comp.os.ms-windows.misc = 21\n",
            "comp.graphics  -  comp.windows.x = 24\n",
            "comp.os.ms-windows.misc  -  comp.sys.ibm.pc.hardware = 21\n",
            "comp.sys.ibm.pc.hardware  -  comp.os.ms-windows.misc = 27\n",
            "comp.sys.ibm.pc.hardware  -  comp.sys.mac.hardware = 26\n",
            "comp.sys.ibm.pc.hardware  -  sci.electronics = 22\n",
            "comp.sys.mac.hardware  -  comp.sys.ibm.pc.hardware = 22\n",
            "comp.windows.x  -  comp.graphics = 32\n",
            "comp.windows.x  -  comp.os.ms-windows.misc = 42\n",
            "rec.sport.baseball  -  rec.sport.hockey = 32\n",
            "sci.electronics  -  comp.sys.ibm.pc.hardware = 22\n",
            "sci.electronics  -  sci.crypt = 30\n",
            "talk.politics.misc  -  talk.politics.guns = 102\n",
            "talk.religion.misc  -  alt.atheism = 45\n",
            "talk.religion.misc  -  soc.religion.christian = 56\n",
            "talk.religion.misc  -  talk.politics.guns = 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎Ya hemos encontrado algunos parámetros como *use_idf* en el *TfidfTransformer*. Los clasificadores tienden a tener muchos parámetros; por ejemplo, *MultinomialNB* incluye un parámetro de suavizado *alpha* y *SGDClassifier* tiene un parámetro de penalización *alpha* y términos configurables de pérdida y penalización en la función objetivo.\n",
        "\n",
        "‎Podemos intentar optimizar estos parámetros para mejorar nuestra clasificación. En lugar de ajustar los parámetros de los diversos componentes de la cadena, es posible ejecutar una búsqueda exhaustiva de los mejores parámetros en una cuadrícula de valores posibles. Probamos todos los clasificadores en palabras o bigrams, con o sin idf, y con un parámetro de penalización de 0.01 o 0.001 para el SVM lineal:\n",
        "\n",
        "Obviamente, una búsqueda tan exhaustiva puede ser costosa. Si tenemos varios núcleos de CPU, podemos decirle al proceso que pruebe estas ocho combinaciones de parámetros en paralelo. Si le damos a este parámetro un valor de -1 a *n_jobs*, grid search detectará cuántos núcleos están instalados y los usará todos\n"
      ],
      "metadata": {
        "id": "7ULwV6xrklU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3)}\n",
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(twenty_train.data[:1000], twenty_train.target[:1000])"
      ],
      "metadata": {
        "id": "ar6aR-NClWsh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‎Los objetos ‎best_score_ y best_params_ almacenan la mejor puntuación media y la configuración de parámetros correspondiente a esa puntuación:"
      ],
      "metadata": {
        "id": "15QUorUbm1C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf.best_score_"
      ],
      "metadata": {
        "id": "yJU9TUNam9U6",
        "outputId": "3264e29c-3f2b-40ec-d87b-07537d51d290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.766"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}